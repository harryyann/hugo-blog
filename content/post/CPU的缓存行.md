---
title: "CPU的多级缓存和cache line"
date: 2021-08-15T19:34:46+08:00
Description: ""
Tags: [golang]
Categories: [golang]
DisableComments: false
draft: false
---

## CPU的多级缓存

随着计算机进入多核时代，CPU处理速度和内存之间的鸿沟越来越大，因此多核CPU都通过缓存行提高CPU和内存的交互效率。

CPU根据型号不同都会有三层以上的缓存行：

![](/images/cacheline/cacheline.png)

如上图，是一个CPU的典型架构，共有三级缓存

- L1缓存：一般都是分成**指令缓存**，和**数据缓存**，分开放。
- L2缓存：从L2缓存开始部分指令和数据，L1和L2缓存都是在一个真实的核中的。
- L3缓存：从L3开始，往往都是一颗CPU中所有核心共享的。

这三级缓存也是**离CPU越远的速度越慢**：

- L1的存取速度：4个CPU时钟周期
- L2的存取速度：11个CPU时钟周期
- L3的存取速度：39个CPU时钟周期
- 内存的存取速度：107个时钟周期

对于存储空间来说：

- L1一般64kb
- L2一般256kb
- L3有2M

## 缓存为什么要设置成三级？

主要基于如下考量：

- 缓存级数越多，多个缓存命中反而速度会下降。
- 由于核心独立缓存的设置，还要考虑多个核心访问同一块数据时的同步问题，明显缓存级数越多，同步过程越复杂

## Cache line

cpu从内存中捞数据时都是一次性捞多个，而不是一次只捞一个字节，这样效率太低。而cpu每次从内存中加载到的数据行大小就是**缓存行(Cache line)**。主流的大小是**64Bytes**，就是16个32位的整型数据，即如果是int32，那就是一次捞16个。

因为cache line缓存行有固定值，所以**L1、L2、L3都得是cache line的倍数**。



## CPU加载内存数据的过程

1. CPU从内存中会以cache line的长度获取数据，并根据LRU算法放进L3缓存中，当L3中的数据访问频繁，就会也被加到L2，L1，依次类推。
2. 如果CPU在计算的过程中另外想要拿到的数据刚好在L1中，就直接拿；没有就是L2拿；再没有就去L3拿，再没有就去内存拿，这里是假设了需要被计算的数据往往都是在内存中是连续存储的。

## 缓存的一致性

CPU的写操作分为两种：

- write back：写操作只写cache，然后再flush到内存。
- write through：写操作同时写cache和内存。

因为内存和cache的性能鸿沟，所以同时写的话太慢了，一般都会采用write back的方案。通过一些**一致性协议**来保证一个核心修改了自己cache的数据，那么其他的核心的cache如果要用到这块数据也会被修改，保证多个核心访问内存中同一行数据时都是一致的，感觉像是cache不存在一样。

## 总结

这方面的知识太过底层，还没有了解的过于深入。其实对于程序员来说，只需要了解到缓存行的存在，并且在写代码时尽量让CPU要访问的数据能命中到缓存行即可，总体来说，就是尽量把CPU可能会连续访问的数据，也存储在内存中靠近的位置。